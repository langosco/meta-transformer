{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Neel's code\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "import json\n",
    "import functools\n",
    "import math\n",
    "\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, nn\n",
    "\n",
    "from optax import adam, rmsprop, sgd\n",
    "\n",
    "import haiku as hk\n",
    "from haiku.initializers import Initializer, Constant, RandomNormal, TruncatedNormal, VarianceScaling\n",
    "\n",
    "import chex\n",
    "\n",
    "\n",
    "import dataclasses\n",
    "from meta_transformer import utils\n",
    "from jax import vmap\n",
    "from meta_transformer.transformer import Transformer\n",
    "from meta_transformer.meta_model import MetaModelClassifier, NetEmbedding, ChunkCNN\n",
    "import numpy as np\n",
    "\n",
    "from typing import Dict, Any, Optional, Tuple, Callable, Mapping, Sequence, Iterable, Union, List\n",
    "from jax.typing import ArrayLike\n",
    "\n",
    "\n",
    "def ctc_net_fn(x: jnp.ndarray,\n",
    "               n_classes: int,\n",
    "               n_conv_layers: int = 1, #3,\n",
    "               kernel_size: tuple = (3, 3),\n",
    "               n_filters: int = 2, #32,\n",
    "               n_fc_layers: int = 1, #3,\n",
    "               fc_width: int = 8, #128,\n",
    "               activation: Callable = nn.relu,\n",
    "               w_init: Initializer = TruncatedNormal()) -> jnp.ndarray:  # TODO: Batchnorm?\n",
    "    convs = [hk.Conv2D(output_channels=n_filters, kernel_shape=kernel_size, padding=\"SAME\", w_init=w_init)\n",
    "             for _ in range(n_conv_layers)]\n",
    "    fcs = [hk.Linear(fc_width, w_init=w_init) for _ in range(n_fc_layers - 1)]\n",
    "\n",
    "    seq = []\n",
    "    for conv in convs:\n",
    "        seq.append(conv)\n",
    "        seq.append(activation)\n",
    "    seq.append(hk.Flatten())\n",
    "    for fc in fcs:\n",
    "        seq.append(fc)\n",
    "        seq.append(activation)\n",
    "    seq.append(hk.Linear(n_classes, w_init=w_init))\n",
    "\n",
    "    net = hk.Sequential(seq)\n",
    "    return net(x)\n",
    "\n",
    "\n",
    "key = random.PRNGKey(4)\n",
    "\n",
    "def tree_shape(tree):\n",
    "    return jax.tree_map(lambda x: x.shape, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv2_d': {'b': (2,), 'w': (3, 3, 1, 2)},\n",
       " 'linear': {'b': (10,), 'w': (2048, 10)}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = hk.without_apply_rng(hk.transform(ctc_net_fn))\n",
    "key, subkey = random.split(key)\n",
    "params = net.init(subkey, jnp.ones((1, 32, 32, 1)), 10)\n",
    "param_shapes = tree_shape(params)\n",
    "param_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['conv2_d_chunk_0', 'linear_chunk_0', 'linear_chunk_1', 'linear_chunk_2', 'linear_chunk_3', 'linear_chunk_4', 'linear_chunk_5', 'linear_chunk_6', 'linear_chunk_7', 'linear_chunk_8', 'linear_chunk_9', 'linear_chunk_10', 'linear_chunk_11', 'linear_chunk_12', 'linear_chunk_13', 'linear_chunk_14', 'linear_chunk_15', 'linear_chunk_16', 'linear_chunk_17', 'linear_chunk_18', 'linear_chunk_19', 'linear_chunk_20'])\n"
     ]
    }
   ],
   "source": [
    "chunk = ChunkCNN(1024, 4*256)\n",
    "chunked_params = chunk(params)\n",
    "#tree_shape(chunked_params)\n",
    "print(chunked_params.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv2_d': {'b': 2, 'w': 18}, 'linear': {'b': 10, 'w': 20480}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_map(lambda x: x.size, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chex.dataclass(frozen=True)\n",
    "class Test:\n",
    "    a: int\n",
    "    b: int\n",
    "\n",
    "    def method(self):\n",
    "        return self.a + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def test_fn(test: Test):\n",
    "    return test.method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(7, dtype=int32, weak_type=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Test(a=5, b=2)\n",
    "test_fn(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unchunk_layers(chunked_params: Dict[str, ArrayLike]) -> Dict[str, jax.Array]:\n",
    "    \"\"\"Unchunk a dictionary of chunked parameters. Both in an output\n",
    "    are flat (one-level) dictionaries.)\"\"\"\n",
    "    unchunked_params = {}\n",
    "    for k, v in chunked_params.items():\n",
    "        layer, _ = k.split(\"_chunk_\")\n",
    "        if layer not in unchunked_params:\n",
    "            unchunked_params[layer] = [v]\n",
    "        else:\n",
    "            unchunked_params[layer].append(v)\n",
    "    unchunked_params = {k: jnp.concatenate(v) for k, v in unchunked_params.items()}\n",
    "    return unchunked_params\n",
    "\n",
    "\n",
    "def get_layer_sizes(params: Dict[str, Dict[str, ArrayLike]]) -> Dict[str, ArrayLike]:\n",
    "    \"\"\"Get the size (weights.size + bias.size) of each layer in params.)\"\"\"\n",
    "    return {k: sum([v.size for v in layer.values()]) \n",
    "            for k, layer in params.items()}\n",
    "\n",
    "\n",
    "def un\n",
    "\n",
    "def nest_params(\n",
    "        params: Dict[str, ArrayLike],\n",
    "        nested_shapes: Dict[str, ArrayLike]) -> Dict[str, Dict[str, jax.Array]]:\n",
    "    \"\"\"Nest a flat dictionary of parameters into a nested dictionary.\"\"\"\n",
    "    nested_params = {}\n",
    "    for layer, shapes in nested_shapes.items():\n",
    "        nested_params[layer] = {}\n",
    "        i = 0\n",
    "        for k, v in shapes.items():\n",
    "            nested_params[layer][k] = params[layer][i:i+v.size].reshape(v)\n",
    "            i += v.size\n",
    "    return nested_params\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class UnChunkCNN:\n",
    "    \"\"\"Inverse of ChunkCNN.\"\"\"\n",
    "    linear_chunk_size: int\n",
    "    conv_chunk_size: int\n",
    "    param_shapes: Dict[str, ArrayLike]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.layer_sizes = get_layer_sizes(self.param_shapes)\n",
    "\n",
    "    def __call__(self, chunked_params: Dict[str, ArrayLike]) -> Dict[str, jax.Array]:\n",
    "        \"\"\"Map chunked CNN weights back to original shape.\"\"\"\n",
    "        # un-chunk the layers:\n",
    "        params = unchunk_layers(chunked_params)\n",
    "        # remove padding:\n",
    "        params = {k: v[:self.layer_sizes[k]] for k, v in params.items()}\n",
    "        # convert back to nested dict and reshape layers:\n",
    "        nested_params = {}\n",
    "        for layer, shapes in self.param_shapes.items():\n",
    "            nested_params[layer] = {\n",
    "                k: params[k][:] for k, v in shapes.items()\n",
    "            }\n",
    "\n",
    "        params = {k: v.reshape(self.param_shapes[k]) for k, v in params.items()}\n",
    "        return params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = unchunk_layers(chunked_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# remove padding and reshape:\n",
    "params = {k: v[:np.prod(self.param_shapes[k])] for k, v in params.items()}\n",
    "params = {k: v.reshape(self.param_shapes[k]) for k, v in params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv2_d': (1024,), 'linear': (21504,)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_shape(unchunk_layers(chunked_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Array slice indices must have static start/stop/step to be used with NumPy indexing syntax. Found slice(None, {'b': (2,), 'w': (3, 3, 1, 2)}, None). To index a statically sized array at a dynamic position, try lax.dynamic_slice/dynamic_update_slice (JAX does not support dynamically sized arrays within JIT compiled functions).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m unchunk \u001b[39m=\u001b[39m UnChunkCNN(\u001b[39m1024\u001b[39m, \u001b[39m4\u001b[39m\u001b[39m*\u001b[39m\u001b[39m256\u001b[39m, param_shapes)\n\u001b[0;32m----> 2\u001b[0m unchunked_params \u001b[39m=\u001b[39m unchunk(chunked_params)\n\u001b[1;32m      3\u001b[0m \u001b[39m# assert same shape\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(tree_shape(params) \u001b[39m==\u001b[39m tree_shape(unchunked_params))\n",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m, in \u001b[0;36mUnChunkCNN.__call__\u001b[0;34m(self, chunked_params)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Map chunked CNN weights back to original shape.\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m params \u001b[39m=\u001b[39m unchunk_layers(chunked_params)\n\u001b[0;32m---> 24\u001b[0m params \u001b[39m=\u001b[39m {k: v[:np\u001b[39m.\u001b[39mprod(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_shapes[k])] \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     25\u001b[0m params \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_shapes[k]) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m params\n",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Map chunked CNN weights back to original shape.\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m params \u001b[39m=\u001b[39m unchunk_layers(chunked_params)\n\u001b[0;32m---> 24\u001b[0m params \u001b[39m=\u001b[39m {k: v[:np\u001b[39m.\u001b[39;49mprod(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_shapes[k])] \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     25\u001b[0m params \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_shapes[k]) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m params\n",
      "File \u001b[0;32m~/.virtualenvs/meta-models/lib/python3.8/site-packages/jax/_src/array.py:343\u001b[0m, in \u001b[0;36mArrayImpl.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    341\u001b[0m   \u001b[39mreturn\u001b[39;00m lax_numpy\u001b[39m.\u001b[39m_rewriting_take(\u001b[39mself\u001b[39m, idx)\n\u001b[1;32m    342\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 343\u001b[0m   \u001b[39mreturn\u001b[39;00m lax_numpy\u001b[39m.\u001b[39;49m_rewriting_take(\u001b[39mself\u001b[39;49m, idx)\n",
      "File \u001b[0;32m~/.virtualenvs/meta-models/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:3908\u001b[0m, in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   3905\u001b[0m       \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39mdynamic_index_in_dim(arr, idx, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   3907\u001b[0m treedef, static_idx, dynamic_idx \u001b[39m=\u001b[39m _split_index_for_jit(idx, arr\u001b[39m.\u001b[39mshape)\n\u001b[0;32m-> 3908\u001b[0m \u001b[39mreturn\u001b[39;00m _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   3909\u001b[0m                unique_indices, mode, fill_value)\n",
      "File \u001b[0;32m~/.virtualenvs/meta-models/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:3917\u001b[0m, in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   3914\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_gather\u001b[39m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   3915\u001b[0m             unique_indices, mode, fill_value):\n\u001b[1;32m   3916\u001b[0m   idx \u001b[39m=\u001b[39m _merge_static_and_dynamic_indices(treedef, static_idx, dynamic_idx)\n\u001b[0;32m-> 3917\u001b[0m   indexer \u001b[39m=\u001b[39m _index_to_gather(shape(arr), idx)  \u001b[39m# shared with _scatter_update\u001b[39;00m\n\u001b[1;32m   3918\u001b[0m   y \u001b[39m=\u001b[39m arr\n\u001b[1;32m   3920\u001b[0m   \u001b[39mif\u001b[39;00m fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/meta-models/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:4169\u001b[0m, in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   4160\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _all(_is_slice_element_none_or_constant(elt)\n\u001b[1;32m   4161\u001b[0m             \u001b[39mfor\u001b[39;00m elt \u001b[39min\u001b[39;00m (start, stop, step)):\n\u001b[1;32m   4162\u001b[0m   msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mArray slice indices must have static start/stop/step to be used \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4163\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mwith NumPy indexing syntax. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4164\u001b[0m          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFound slice(\u001b[39m\u001b[39m{\u001b[39;00mstart\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mstop\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mstep\u001b[39m}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4167\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mdynamic_update_slice (JAX does not support dynamically sized \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4168\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39marrays within JIT compiled functions).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 4169\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(msg)\n\u001b[1;32m   4170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m core\u001b[39m.\u001b[39mis_constant_dim(x_shape[x_axis]):\n\u001b[1;32m   4171\u001b[0m   msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mCannot use NumPy slice indexing on an array dimension whose \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4172\u001b[0m          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msize is not statically known (\u001b[39m\u001b[39m{\u001b[39;00mx_shape[x_axis]\u001b[39m}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4173\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mTry using lax.dynamic_slice/dynamic_update_slice\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: Array slice indices must have static start/stop/step to be used with NumPy indexing syntax. Found slice(None, {'b': (2,), 'w': (3, 3, 1, 2)}, None). To index a statically sized array at a dynamic position, try lax.dynamic_slice/dynamic_update_slice (JAX does not support dynamically sized arrays within JIT compiled functions)."
     ]
    }
   ],
   "source": [
    "unchunk = UnChunkCNN(1024, 4*256, param_shapes)\n",
    "unchunked_params = unchunk(chunked_params)\n",
    "# assert same shape\n",
    "print(tree_shape(params) == tree_shape(unchunked_params))\n",
    "#chex.assert_trees_all_close(params, unchunked_params, rtol=1, atol=1)\n",
    "jax.tree_map(lambda x, y: jnp.allclose(x, y), params, unchunked_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import dataclasses\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class UnChunkCNN:\n",
    "    linear_chunk_size: int\n",
    "    conv_chunk_size: int\n",
    "    original_param_shapes: Dict[str, Dict[str, Tuple[int]]]\n",
    "\n",
    "    def __call__(self, chunked_params: dict) -> dict:\n",
    "        \"\"\"Merge CNN weight chunks back into the original parameters.\"\"\"\n",
    "\n",
    "        def unchunk_layers():\n",
    "            unchunked_params = {}\n",
    "            for key, chunk in chunked_params.items():\n",
    "                layer_key, _, chunk_idx = key.rpartition('_chunk_')\n",
    "                chunk_idx = int(chunk_idx)\n",
    "                unchunked_params.setdefault(layer_key, []).extend([None] * (1 + chunk_idx - len(unchunked_params[layer_key])))\n",
    "                unchunked_params[layer_key][chunk_idx] = chunk\n",
    "            return unchunked_params\n",
    "\n",
    "        def concatenate_chunks(unchunked_params):\n",
    "            return {k: jnp.concatenate(vs) for k, vs in unchunked_params.items()}\n",
    "\n",
    "        def reshape_layer_params(layer_key, layer_data):\n",
    "            layer_shapes = self.original_param_shapes[layer_key]\n",
    "            layer_params = {}\n",
    "            start_idx = 0\n",
    "            for param_key, param_shape in layer_shapes.items():\n",
    "                param_size = jnp.prod(jnp.array(param_shape))\n",
    "                layer_data_sliced = layer_data[start_idx:start_idx + param_size]\n",
    "                layer_params[param_key] = jnp.reshape(layer_data_sliced, param_shape)\n",
    "                start_idx += param_size\n",
    "            return layer_params\n",
    "\n",
    "        unchunked_params = unchunk_layers()\n",
    "        concatenated_params = concatenate_chunks(unchunked_params)\n",
    "        original_params = {layer_key: reshape_layer_params(layer_key, layer_data) for layer_key, layer_data in concatenated_params.items()}\n",
    "\n",
    "        return original_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import dataclasses\n",
    "from typing import Dict, Tuple\n",
    "import re\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class UnChunkCNN:\n",
    "    linear_chunk_size: int\n",
    "    conv_chunk_size: int\n",
    "    original_param_shapes: Dict[str, Dict[str, Tuple[int]]]\n",
    "\n",
    "    def __call__(self, chunked_params: dict) -> dict:\n",
    "        \"\"\"Merge CNN weight chunks back into the original parameters.\"\"\"\n",
    "        # First, unchunk the layers\n",
    "        unchunked_params = {}\n",
    "        for key, chunk in chunked_params.items():\n",
    "            layer_key, _, chunk_idx = key.rpartition('_chunk_')\n",
    "            chunk_idx = int(chunk_idx)\n",
    "\n",
    "            if layer_key not in unchunked_params:\n",
    "                unchunked_params[layer_key] = []\n",
    "\n",
    "            while len(unchunked_params[layer_key]) <= chunk_idx:\n",
    "                unchunked_params[layer_key].append(None)\n",
    "\n",
    "            unchunked_params[layer_key][chunk_idx] = chunk\n",
    "\n",
    "        # Then, concatenate the chunks\n",
    "        unchunked_params = {\n",
    "            k: jnp.concatenate(vs) for k, vs in unchunked_params.items()\n",
    "        }\n",
    "\n",
    "        # Finally, reshape the parameters into their original shapes\n",
    "        original_params = {}\n",
    "        for layer_key, layer_data in unchunked_params.items():\n",
    "            if layer_key not in self.original_param_shapes:\n",
    "                raise ValueError(f\"Layer key {layer_key} not found in original_param_shapes\")\n",
    "\n",
    "            layer_shapes = self.original_param_shapes[layer_key]\n",
    "\n",
    "            layer_params = {}\n",
    "            start_idx = 0\n",
    "            for param_key, param_shape in layer_shapes.items():\n",
    "                param_size = jnp.prod(jnp.array(param_shape))\n",
    "                layer_params[param_key] = jnp.reshape(\n",
    "                    layer_data[start_idx:start_idx + param_size], param_shape\n",
    "                )\n",
    "                start_idx += param_size\n",
    "\n",
    "            original_params[layer_key] = layer_params\n",
    "\n",
    "        return original_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunked_params = chunk_cnn(params, 1024, 256)\n",
    "# jax.tree_util.tree_map(lambda x: x.shape, chunked_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.23105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.count_params(params) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv2_d': {'b': (2, 32), 'w': (2, 3, 3, 1, 32)},\n",
       " 'conv2_d_1': {'b': (2, 32), 'w': (2, 3, 3, 32, 32)},\n",
       " 'conv2_d_2': {'b': (2, 32), 'w': (2, 3, 3, 32, 32)},\n",
       " 'linear': {'b': (2, 128), 'w': (2, 32768, 128)},\n",
       " 'linear_1': {'b': (2, 128), 'w': (2, 128, 128)},\n",
       " 'linear_2': {'b': (2, 10), 'w': (2, 128, 10)}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = utils.tree_stack([params, params])\n",
    "jax.tree_map(lambda x: x.shape, stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(params: dict):\n",
    "    net = MetaModelClassifier(\n",
    "        model_size=4*32, \n",
    "        num_classes=10, \n",
    "        transformer=Transformer(\n",
    "            num_heads=4,\n",
    "            num_layers=2,\n",
    "            key_size=32,\n",
    "            dropout_rate=0.0,\n",
    "        ))\n",
    "    return net(params)\n",
    "\n",
    "\n",
    "model = hk.transform(model_fn)\n",
    "    \n",
    "key, subkey = random.split(key)\n",
    "meta_params = jax.jit(model.init)(subkey, stacked)\n",
    "model_forward = jax.jit(model.apply)\n",
    "key, subkey = random.split(key)\n",
    "out = model_forward(meta_params, subkey, stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.21297008, -0.2555064 , -0.22231516,  1.1032469 , -0.36101305,\n",
       "        -0.2299385 , -0.43089166, -0.07022727, -1.0288874 , -0.95691407],\n",
       "       [-0.21297008, -0.2555064 , -0.22231516,  1.1032469 , -0.36101305,\n",
       "        -0.2299385 , -0.43089166, -0.07022727, -1.0288874 , -0.95691407]],      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0] - out[1] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
