{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3564aed0-88a3-45fe-8a13-fa26309fb5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.303019228744507, 0.1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable, Optional\n",
    "import json\n",
    "import functools\n",
    "import math\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, nn\n",
    "\n",
    "from optax import adam, rmsprop, sgd\n",
    "\n",
    "import haiku as hk\n",
    "from haiku.initializers import Initializer, Constant, RandomNormal, TruncatedNormal, VarianceScaling\n",
    "from meta_transformer import utils\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from meta_transformer import module_path, preprocessing, backdoors_utils, torch_utils\n",
    "from meta_transformer.backdoors_utils import test, testloader\n",
    "\n",
    "DATA_DIR = os.path.join(module_path, 'data/david_backdoors/cifar10')\n",
    "\n",
    "model = torch_utils.CNN_small_no_drop().to('cuda')\n",
    "test(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a922129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN_small_no_drop(nn.Module):\n",
    "    def __init__(self, config=None):\n",
    "        super(CNN_small_no_drop, self).__init__()\n",
    "\n",
    "        #add batchnorm before each RelU make network happy\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f4c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_small_no_drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58edc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_process_nets(name: str, n: int):\n",
    "    path_to_processed = os.path.join(\n",
    "            module_path, \"data/cache/depoisoning\", name)\n",
    "    os.makedirs(os.path.dirname(path_to_processed), exist_ok=True)\n",
    "\n",
    "    if os.path.exists(path_to_processed) and n == 10000:\n",
    "        inputs = np.load(path_to_processed)\n",
    "    else:\n",
    "        inputs = torch_utils.load_pytorch_nets(\n",
    "            n=n, data_dir=os.path.join(DATA_DIR, name)\n",
    "        )\n",
    "        unpreprocess = preprocessing.get_unpreprocess(inputs[0], CHUNK_SIZE)\n",
    "        inputs = np.stack([preprocessing.preprocess(inp, CHUNK_SIZE)[0]\n",
    "                      for inp in inputs])\n",
    "\n",
    "    if n == 10000:\n",
    "        np.save(path_to_processed, inputs)\n",
    "\n",
    "    return inputs / DATA_STD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e6c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sketch of testing code\n",
    "# get accuracy of depoisoned models from the meta-model outputs\n",
    "outputs = None # array of flattened NN weights\n",
    "params = unpreprocess(outputs) # dict of NN weights\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
